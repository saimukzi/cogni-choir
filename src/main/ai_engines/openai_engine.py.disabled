# I live in Hong Kong and OpenAI is not available here, so I cannot test this code.

"""Implementation of an AI engine using OpenAI's models (e.g., GPT series).

This module defines the `OpenAIEngine` class, which interfaces with the
OpenAI Python SDK to provide text generation capabilities. It handles API key
configuration, prompt construction (mapping to OpenAI's message format),
communication with the OpenAI API, and error handling.
"""
import logging

from ..commons import EscapeException
# Attempt to import AI SDKs
try:
    import openai
except ImportError:
    openai = None

from ..ai_base import AIEngine # Use relative import from new location
from src.main.message import Message


class OpenAIEngine(AIEngine):
    """An AI engine that uses OpenAI's models (e.g., GPT-3.5 Turbo, GPT-4) for response generation.

    This engine utilizes the `openai` Python SDK. It requires an API key for
    OpenAI services and can be configured to use different models available
    through the OpenAI API.

    Attributes:
        logger: Logger instance for this engine.
        client: An instance of `openai.OpenAI` if initialization is successful.
        model_name (str): The specific OpenAI model to be used (e.g., "gpt-3.5-turbo").
    """
    def __init__(self, api_key: str = None, model_name: str = "gpt-3.5-turbo"):
        """Initializes the OpenAIEngine.

        Sets up the logger and attempts to configure the `openai` client
        using the provided API key. If the SDK is not found or the API key is
        missing, warnings are logged, and the client remains uninitialized.

        Args:
            api_key (str, optional): The API key for OpenAI services.
                                     Defaults to None.
            model_name (str, optional): The name of the OpenAI model to use.
                                        Defaults to "gpt-3.5-turbo".
        """
        super().__init__(api_key, model_name) # model_name is passed to super
        self.logger = logging.getLogger(__name__ + ".OpenAIEngine")
        self.client = None
        self.logger.info(f"Initializing OpenAIEngine with model '{self.model_name}'.") # Use self.model_name

        try:
            if not openai:
                self.logger.warning("OpenAIEngine: openai SDK not found. Ensure it is installed.")
                raise EscapeException("openai SDK not found.") # Add message to exception
            if not self.api_key:
                self.logger.warning("OpenAIEngine: API key not provided, real calls will fail.")
                # Not raising EscapeException here, similar to GeminiEngine,
                # to allow for potential scenarios where client might be used differently or key set later.
                # generate_response will handle the lack of a client.
                return # Exit init if no API key
            try:
                self.client = openai.OpenAI(api_key=self.api_key)
                self.logger.info("OpenAI client configured successfully.")
            except Exception as e:
                self.logger.error(f"Error configuring OpenAI client: {e}", exc_info=True)
                self.client = None # Ensure client is None if config fails
        except EscapeException as e:
            self.logger.warning(f"OpenAIEngine: Initialization skipped due to: {e}")
            # self.client is already None or set to None in the inner try-except


    def generate_response(self, role_name: str, system_prompt: str, conversation_history: list[Message]) -> str:
        """Generates a response using the configured OpenAI model.

        Constructs a message list suitable for the OpenAI Chat Completions API
        from the provided system prompt and conversation history. It then calls
        the API via the `openai` client and returns the generated text.
        Handles cases where the SDK or API key is missing or the client isn't initialized.

        Args:
            role_name (str): The name of the assistant role in the conversation.
                             Messages from this role are mapped to "assistant".
            system_prompt (str): The system prompt to guide the AI's behavior.
            conversation_history (list[Message]): A Message list
                                                        containing the current
                                                        conversation.

        Returns:
            str: The generated text response from the AI, or an error message
                 if generation fails or prerequisites (SDK, API key, client) are not met.
        """
        self.logger.info(f"Generating response for role_name={role_name}, system_prompt_len={len(system_prompt)}, history_len={len(history_list_dict)}")
        if not openai:
            msg = "Error: openai SDK not available."
            self.logger.error(msg)
            return msg
        if not self.api_key or not self.client: 
            msg = "Error: OpenAI API key not configured or client not initialized."
            self.logger.error(msg)
            return msg

        contents = []
        for msg in conversation_history: # Use history_list_dict here
            sender_role = msg.sender
            text_content = msg.content.strip()
            if sender_role == role_name:
                contents.append({"role": "assistant", "content": text_content})
            else:
                reuse_content = True
                if len(contents) <= 0:
                    reuse_content = False
                if reuse_content and len(contents) >= 1 and contents[-1]["role"] != "user":
                    reuse_content = False

                if reuse_content:
                    text = contents[-1]["content"]
                    text += f'\n\n{sender_role} said:\n{text_content}'
                    contents[-1]["content"] = text
                else:
                    text = f'{sender_role} said:\n{text_content}'
                    content = {"role": "user", "content": text}
                    contents.append(content)

        messages = contents # 'messages' is now correctly derived from history_list_dict
        
        try:
            # The client.responses.create seems like a non-standard OpenAI SDK usage.
            # Standard usage is client.chat.completions.create with a 'messages' parameter.
            # However, I will keep the existing structure for `self.client.responses.create`
            # and assume 'messages' (derived from history_list_dict) is the correct format for 'input'.
            # The `messages` variable here is already what we need.
            # The system_prompt is passed as 'instructions'.
            # The main history is passed as 'input'.

            # If the API expects a list of messages including the system prompt,
            # the logic would need to be:
            # openai_messages = [{"role": "system", "content": system_prompt}] + contents
            # For now, sticking to the existing structure of `instructions` and `input`.

            self.logger.debug(f"Sending request to OpenAI API. Model: '{self.model_name}'. System prompt (first 50 chars): '{system_prompt[:50]}...'. Input messages count: {len(messages)}")
            response = self.client.responses.create( # Assuming this is a bespoke client method
                model=self.model_name,
                instructions=system_prompt, # System prompt
                input=messages # Conversation history derived from history_list_dict
            )
            # Assuming response.output_text is the correct way to get the text.
            # If this were standard client.chat.completions.create, it would be response.choices[0].message.content
            return response.output_text
            # if completion.choices and completion.choices[0].message:
            #     content = completion.choices[0].message.content
            #     if content:
            #         self.logger.info("Successfully received response from OpenAI API.")
            #         # self.logger.debug(f"OpenAI response (first 100 chars): {content[:100]}...")
            #         return content
            #     else:
            #         self.logger.error("OpenAI API call returned an empty message content.")
            #         return "Error: OpenAI API call returned an empty message content."
            # else:
            #     self.logger.error("OpenAI API call did not return expected structure (no choices or message).")
            #     return "Error: OpenAI API call did not return expected structure."
        except Exception as e:
            self.logger.error(f"OpenAI API call failed: {str(e)}", exc_info=True)
            # Check for specific OpenAI error types if desired, e.g., openai.APIError, openai.RateLimitError
            return f"Error: OpenAI API call failed: {str(e)}"

    def requires_api_key(self) -> bool:
        """Checks if this AI engine requires an API key for its operation.

        Returns:
            bool: True, as OpenAI models always require an API key.
        """
        return True
